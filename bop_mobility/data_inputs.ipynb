{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an auxiliary script to the main scripts calculating the consumption intensity for the products in each of the different Baskets of Products (BoPs) within the european averaged citizen consumption footprint by country project.\n",
    "\n",
    "It contains four functions: *read_file*, *filter_file*, *inventory_dtype* and *population*, which are to be use for loading additional information from sources different from [PRODCOM](https://ec.europa.eu/eurostat/web/prodcom/data/database) and [COMEXT](https://ec.europa.eu/eurostat/web/international-trade-in-goods/data/database) for which the pyhton package [*eurostat*](https://pypi.org/project/eurostat/) will be used. \n",
    "\n",
    "- *read_file*, *filter_file* and *inventory_dtype* are focused on excel and csv files.\n",
    "- *population* extracts information on population per country and year from EUROSTAT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "In addition to Python 3.3 built-in packages, some other specific packages, such as *pandas* or *numpy* will have to be loaded too. Besides, although this can be modified anytime, the functions have been created assuming there will be two folders, *input* and *outputs* in the same directory where the present script is, containing respectively the input files to be read and the future output files resulting from the application of this script function's on input files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import eurostat as estat\n",
    "import math\n",
    "\n",
    "INPUTS_FOLDER = \"../inputs\"\n",
    "OUTPUTS_FOLDER = \"../outputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name, file_folder, firstrow, sheetname, data_type_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads the excel file containing the BoPs information.\n",
    "    \n",
    "    :param file_name : name of the file including extension.\n",
    "    :type file_name : str.\n",
    "    :param file_folder : folder where the file is.\n",
    "    :type file_folder : str.\n",
    "    :param firstrow :  first row with data counting from the top, being the first one row number 0.\n",
    "    :type firstrow : int.\n",
    "    :param sheetname : name of the sheet of interest within the document. It can also be a number, beginning with 0 for the 1st sheet.\n",
    "    :type sheetname : str/int.\n",
    "    :param data_type_dict : the data type of each of the columns in the file.\n",
    "    :type data_type_dict : dict.\n",
    "    :return : file content.\n",
    "    :type return : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = os.path.join(file_folder, file_name)\n",
    "        \n",
    "    if file_name.endswith((\".xlsx\", \".xls\")):\n",
    "\n",
    "        df = pd.read_excel(file_path, dtype = data_type_dict, sheet_name = sheetname, skiprows = list(range(firstrow-1)))\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif file_name.endswith(\".csv\"):\n",
    "        \n",
    "        df = pd.read_csv(file_path, dtype = data_type_dict, skiprows = list(range(firstrow-1)), encoding = \"latin-1\")\n",
    "        \n",
    "       \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Wrong file extension\")\n",
    "        \n",
    "        return\n",
    "        \n",
    "   \n",
    "    #Replace nan strings by nan's numpy    \n",
    "    df = df.replace([\"nan\", \"NaN\"], np.nan)\n",
    "    #Delete all columns where all rows are nan\n",
    "    df = df.dropna(how = 'all')\n",
    "    #Delete all rows where all columns are nan\n",
    "    df = df.dropna(axis = \"columns\", how = 'all')\n",
    "    \n",
    "    return(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_file(items, input_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the column containing the items and extracts the rows where these are.\n",
    "    \n",
    "    :param items : elements of interst. For the \"Upscale.xlsx\" these could be either products groups, basket of product or representative products.\n",
    "    :type items : list.\n",
    "    :param input_df : contains the information.\n",
    "    :type ups_df : data frame.\n",
    "    :return : filtered information.\n",
    "    :type return : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    #List all columns\n",
    "    input_cols = input_df.columns\n",
    "    \n",
    "    #Creation of a list\n",
    "    filtered_cols = []\n",
    "    \n",
    "    # It filters the file according to the first column where the item is found. \n",
    "    # Select only the FIRST column, beginning from the left, that contains the items of interest.\n",
    "                          \n",
    "    for col in input_cols:\n",
    "        \n",
    "        #From all the items demanded, it checks their existence in the column\n",
    "        existing = [i for i in items if i in input_df[col].tolist()]\n",
    "        #From all the items demanded, it checks their existence in the column\n",
    "        missing = [i for i in items if i not in input_df[col].tolist()]\n",
    "        \n",
    "        #If all the items are in the column\n",
    "        if len(existing) == len(items):\n",
    "            \n",
    "            input_filtered = input_df[input_df[col].isin(items)]\n",
    "            \n",
    "            #Each column that has been checked is added, given the condition that all items are in the column\n",
    "            filtered_cols.append(col)\n",
    "            \n",
    "            break\n",
    "            \n",
    "        #If some items are in the colum\n",
    "        elif len(missing) < len(items):\n",
    "            \n",
    "            print(\"Some items were found in {}\".format(col))\n",
    "            \n",
    "        #TODO check with Laura\n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "    print(\"All the provided items are in columns: {}\".format(filtered_cols))\n",
    "            \n",
    "    # It makes the list of unique values in the list of filtered_cols - This could be deleted\n",
    "    unique_filtered_cols = list(set(filtered_cols))\n",
    "            \n",
    "    return(input_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inventory_dtype():\n",
    "    \n",
    "    dtype = {\"prod_codes\" : str, \"EXP_COEF\" : float, \"IMP_COEF\" : float, \"PROD_COEF\" : float, \"components\" : str,\n",
    "                                              \"split\" : float, \"DC_COEF\" : str, \"DC_PRODS\" : str, \"FBS_UPS\" : float, \"FAO_group\":str}\n",
    "    \n",
    "    return(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population(start_year, end_year):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves information on the population of all european countries in the selected years from EUROSTAT.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    \n",
    "    \"\"\"\n",
    "    # It gets dataframe from Eurostat ()\n",
    "    pop_df = estat.get_data_df(\"demo_r_d2jan\", flags=False)\n",
    "    \n",
    "    #Defined columns\n",
    "    cols= pop_df.columns\n",
    "    #Filters total sex\n",
    "    pop_df = pop_df[pop_df[\"sex\"] == \"T\"]\n",
    "    #Filters total age\n",
    "    pop_df = pop_df[pop_df[\"age\"] == \"TOTAL\"]\n",
    "    #Range for time period\n",
    "    years = list(range(int(start_year), (int(end_year)+1)))\n",
    "    \n",
    "    #Check that years are not in columns to inform about missing years data - variable could be called y = missing years\n",
    "    missing_y = [y for y in years if y not in cols]\n",
    "    \n",
    "    if missing_y:\n",
    "        print(\"These years are not in the database: \", missing_y)\n",
    "        \n",
    "    #When the years are in the dataframe\n",
    "    new_years = [y for y in years if y in cols]\n",
    "    #Creation of a list columns with the indicated information + the listed years\n",
    "    new_cols = [\"unit\", \"sex\", \"age\", \"geo\\\\time\"] + new_years\n",
    "    #Selection of the abovecreated list from the entire dataframe\n",
    "    pop_df = pop_df[new_cols]\n",
    "    #List of the codes for countries\n",
    "    area_shorthand = pop_df[\"geo\\\\time\"].tolist()\n",
    "    \n",
    "    country_dict = {'AT': 'Austria', 'BE': 'Belgium', 'BG': 'Bulgaria',\n",
    " 'CY': 'Cyprus', 'CZ': 'Czechia', 'DE': 'Germany', 'DK': 'Denmark', 'EE': 'Estonia', 'EL': 'Greece', 'ES': 'Spain', 'FI': 'Finland',\n",
    " 'FR': 'France', 'HR': 'Croatia', 'HU': 'Hungary', 'IE': 'Ireland', 'IT': 'Italy', 'LT': 'Lithuania','LU': 'Luxemburg', 'LV': 'Latvia',\n",
    "    'MT': 'Malta', 'NL': 'Netherlands', 'PL': 'Poland', \"UK\" : \"United Kingdom\", 'PT': 'Portugal', 'RO': 'Romania', 'SE': 'Sweden', 'SI': 'Slovenia', 'SK': 'Slovakia'}\n",
    "    #Filter all the country codes in a list of those countries in country_dict for EU-28    \n",
    "    country_shorthand = [a for a in area_shorthand if a in country_dict.keys()]\n",
    "    #Filter the dataframe\n",
    "    pop_df = pop_df[pop_df[\"geo\\\\time\"].isin(country_shorthand)]\n",
    "    #List the countries\n",
    "    coun_sh_col = pop_df[\"geo\\\\time\"].tolist()\n",
    "    #Assign the country name to the codes according to the dictionary\n",
    "    country_names = [country_dict[csh] for csh in coun_sh_col]\n",
    "    #Creation of a column with the names of the countries. This is done to enhance the link it with prodcom and comext and fao (harmonization)\n",
    "    pop_df[\"DECL\"] = country_names\n",
    "    #Delete useless columns, remaining only population data and country information\n",
    "    pop_df = pop_df.drop([\"unit\", \"sex\", \"age\", \"geo\\\\time\"], axis = 1)\n",
    "    #Sort by alphabetical order according to country name\n",
    "    pop_df.sort_values(by = [\"DECL\"])\n",
    "    #Years (which are now colums) are transformed into a unique column + incl. Change names of columns\n",
    "    pop_df = pop_df.set_index([\"DECL\"]).stack().reset_index(\"DECL\").reset_index().rename(columns = {\"index\" : \"Year\", 0 : \"Population\"})\n",
    "    \n",
    "    # Calculate EU28 population by adding up all the countries populations for each year.\n",
    "    #Aggregate data by year \n",
    "    pop_eu28 = pop_df.groupby(\"Year\").sum()\n",
    "    #Since the previous function changes columns into indexes, we need this function to transform it back to column\n",
    "    pop_eu28.reset_index(inplace = True)\n",
    "    #In the decl column, add the country EU28 - Check the output of this\n",
    "    pop_eu28[\"DECL\"] = [\"Eu28Intra\"] * len(years)\n",
    "    #Add EU28 datafram to pop_df\n",
    "    pop_df = pd.concat([pop_df, pop_eu28], sort = True)\n",
    "    \n",
    "    return(pop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
